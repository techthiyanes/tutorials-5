# Runhouse Basics ğŸ§‘â€ğŸ« - Fine-tuning BERT on Multiple GPUs and Deploying

_Watch time: ~10 minutes_

Runhouse is designed to make interacting with shared, heterogeneous
hardware and data resources feel easy and natural. We'll test this 
by performing the various stages of a simple ML workflow all in
eager Python, touching several types of hardware and data 
storage. You'll see how many of the resources we create along
the way are general-purpose, and suitable to be reused among 
a team.

## 01 Distributing preprocessing across many CPUs with Hugging Face ğŸ¤— Datasets

Video (WIP)

## 02 Scaling BERT Fine-tuning with Hugging Face ğŸ¤— Accelerate

Video (WIP)

## 03 Evaluating the model before deploying for inference

Video (WIP)

## 04 A simple inference service with zero-downtime deployment

Video (WIP)

## 05 Pipelining: A service taking dataset to deployment

Video (WIP)

## 06 The P2R Path: Iterating on a production pipeline in Colab

Video (WIP)
