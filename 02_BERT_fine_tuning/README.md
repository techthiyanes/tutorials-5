# A Runhouse Pipeline üë©‚Äçüîß - Fine-tuning BERT on Multiple GPUs and Deploying

_Watch time: ~10 minutes_

Runhouse is designed to make interacting with shared, heterogeneous
hardware and data resources feel easy and natural. We'll test this 
by performing the various stages of a simple ML workflow all in
eager Python, touching several types of hardware and data 
storage. You'll see how many of the resources we create along
the way are general-purpose, and suitable to be reused among 
a team.

This tutorial will demonstrate BERT fine-tuning for sentiment analysis
using the Yelp reviews dataset, largely based on this [Hugging Face 
tutorial](https://huggingface.co/docs/transformers/training).

## 01 Distributing preprocessing across many CPUs with Hugging Face ü§ó Datasets

Video (WIP)

## 02 Scaling BERT Fine-tuning with Hugging Face ü§ó Accelerate

Video (WIP)

## 03 Evaluating the model before deploying for inference

Video (WIP)

## 04 A simple inference service with zero-downtime deployment

Video (WIP)

## 05 Pipelining: A service taking dataset to deployment

Video (WIP)

## 06 The P2R Path: Iterating on a production pipeline in Colab

Video (WIP)
