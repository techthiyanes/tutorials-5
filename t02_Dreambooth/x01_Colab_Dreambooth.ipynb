{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_jAYfxEcc9h"
      },
      "source": [
        "### Install Runhouse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nmEjtRsb3Ok"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/run-house/runhouse.git@latest_patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1hPCDiHeSkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c22679-e925-44a9-832b-497e2ee167c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2022-12-13 05:38:24,002 | Loaded Runhouse config from /root/.rh/config.yaml\n"
          ]
        }
      ],
      "source": [
        "import runhouse as rh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_WFF9nyRtCB"
      },
      "source": [
        "### Login to Runhouse to load in secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UnHVWUYplGV"
      },
      "outputs": [],
      "source": [
        "# You can add token=<your token> if you want to be able to run this without pasting into stdin\n",
        "rh.login(download_secrets=True, download_config=True, interactive=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G8NcBOUF4sb"
      },
      "outputs": [],
      "source": [
        "# Only if you're using GCP and running inside Colab!\n",
        "!gcloud init\n",
        "!gcloud auth application-default login\n",
        "!cp -r /content/.config/* ~/.config/gcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s_uGZSssCrV"
      },
      "outputs": [],
      "source": [
        "# Check that secrets are loaded in properly and at least one cloud is ready to use.\n",
        "!sky check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dreambooth Training\n",
        "\n",
        "Start by creating our training service."
      ],
      "metadata": {
        "id": "wKD0hd_DIlbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = rh.cluster(name='rh-a10x', instance_type='A100:1')  # On GCP and Azure\n",
        "# gpu = rh.cluster(name='rh-a10x', instance_type='g5.2xlarge', provider='aws')  # On AWS\n",
        "\n",
        "training_function_gpu = rh.send(\n",
        "    fn='https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py:main',\n",
        "    hardware=gpu,\n",
        "    reqs=['pip:./diffusers'],\n",
        "    name='train_dreambooth')\n",
        "training_function_gpu.run_setup(['mkdir dreambooth'])\n",
        "gpu.run_python(['import torch; torch.backends.cuda.matmul.allow_tf32 = True; '\n",
        "                'torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True'])"
      ],
      "metadata": {
        "id": "j6yIxheMIm_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to upload some images."
      ],
      "metadata": {
        "id": "EcmMCigxFqKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "MFPJH1XxFpt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll send those images to our cluster."
      ],
      "metadata": {
        "id": "lIy3LqIQFsrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_images_dir = 'images'\n",
        "images_path = Path(input_images_dir)\n",
        "images_path.mkdir(exist_ok=True)\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "  shutil.move(filename, images_path / filename)\n",
        "\n",
        "remote_image_dir = 'dreambooth/instance_images'\n",
        "rh.folder(url=input_images_dir).to(fs=gpu, url=remote_image_dir)"
      ],
      "metadata": {
        "id": "q6WY6HFZFuZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll generate the arguments into the training function (and call this function on the cluster to avoid having to clone it down locally)."
      ],
      "metadata": {
        "id": "kSDY8azOFzk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_train_args = rh.send(\n",
        "    fn='https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py:parse_args',\n",
        "    hardware=gpu, reqs=[])\n",
        "train_args = create_train_args(input_args=['--pretrained_model_name_or_path', 'stabilityai/stable-diffusion-2-base',\n",
        "                                            '--instance_data_dir', remote_image_dir,\n",
        "                                            '--instance_prompt', f'a photo of sks {class_name}'])\n",
        "train_args.train_text_encoder = True\n",
        "train_args.class_data_dir = 'dreambooth/class_images'\n",
        "train_args.output_dir = 'dreambooth/output'\n",
        "train_args.mixed_precision = 'bf16'\n",
        "train_args.with_prior_preservation = True\n",
        "train_args.prior_loss_weight = 1.0\n",
        "train_args.class_prompt = f\"a photo of {class_name}\"\n",
        "train_args.resolution = 512\n",
        "train_args.train_batch_size = 4\n",
        "train_args.gradient_checkpointing = True\n",
        "train_args.learning_rate = 1e-6\n",
        "train_args.lr_scheduler = \"constant\"\n",
        "train_args.lr_warmup_steps = 0\n",
        "train_args.num_class_images = 200\n",
        "train_args.checkpointing_steps = 400\n",
        "# train_args.resume_from_checkpoint = 'latest'\n",
        "train_args.max_train_steps = 1200"
      ],
      "metadata": {
        "id": "DCazU_tzFyr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And initiate training:"
      ],
      "metadata": {
        "id": "m_ChQERQGC9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_function_gpu(train_args)"
      ],
      "metadata": {
        "id": "SxpLzmqaGEON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n",
        "\n",
        "Now we can use our existing Stable Diffusion service to run inferences on this model:"
      ],
      "metadata": {
        "id": "T6V06o3CKMO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_gpu = rh.Send.from_name(name='sd_generate')"
      ],
      "metadata": {
        "id": "j9XWAhcJKdBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'dreambooth/output'\n",
        "images = generate_gpu(my_prompt,\n",
        "                      model_id=model_path,\n",
        "                      num_images=4, guidance_scale=7.5,\n",
        "                      steps=100)"
      ],
      "metadata": {
        "id": "oXdp1NzHKlxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[image.show() for image in images]"
      ],
      "metadata": {
        "id": "8jUmi71SKmj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}